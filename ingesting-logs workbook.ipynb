{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf16336-a7e6-4bd6-a551-04b7f796f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa752bb0-8e97-4101-8ec4-2cdfc7f727df",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///inventory.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bd2fdd-5173-40c6-a856-983d4beef7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchases.csv\n",
      "purchase_prices.csv\n",
      "vendor_invoice.csv\n",
      "begin_inventory.csv\n",
      ".ipynb_checkpoints\n",
      "end_inventory.csv\n",
      "sales.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29b692f5-e069-447c-91d2-93f1bd50792c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchases.csv: (2372474, 16)\n",
      "purchase_prices.csv: (12261, 9)\n",
      "vendor_invoice.csv: (5543, 10)\n",
      "begin_inventory.csv: (206529, 9)\n",
      "end_inventory.csv: (224489, 9)\n",
      "sales.csv: (12825363, 14)\n"
     ]
    }
   ],
   "source": [
    "# Iterate through files in 'data' directory\n",
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join('data', file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"{file}: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32ab8a8e-6c57-40ef-8e08-b8df475591a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing purchases.csv (344.83 MB)...\n",
      "Processing purchase_prices.csv (1.00 MB)...\n",
      "Processing vendor_invoice.csv (0.49 MB)...\n",
      "Processing begin_inventory.csv (16.64 MB)...\n",
      "Processing end_inventory.csv (18.10 MB)...\n",
      "Processing sales.csv (1522.76 MB)...\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join('data', file)\n",
    "        size_mb = os.path.getsize(file_path) / (1024 * 1024)\n",
    "        print(f\"Processing {file} ({size_mb:.2f} MB)...\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e1b5f04-90ba-4b4e-a771-58c468fc6693",
   "metadata": {},
   "source": [
    "Read CSV in chunks -> recommended for larger csv(more than 1Gb) file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe836564-a7ae-445f-ac48-69f0fee0a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_csv_in_chunks(file_path, table_name, engine, chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Ingests a large CSV file into a database in chunks.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the CSV file.\n",
    "        table_name (str): Name of the target table.\n",
    "        engine (SQLAlchemy Engine): SQLAlchemy database engine.\n",
    "        chunk_size (int): Number of rows per chunk.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    first_chunk = True\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        if_exists_mode = 'replace' if first_chunk else 'append'\n",
    "        chunk.to_sql(table_name, con=engine, if_exists=if_exists_mode, index=False)\n",
    "        first_chunk = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e31f40c-dffb-4c8c-bdb4-e7c9634a0065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunked ingesting: purchases.csv\n",
      "Chunked ingesting: purchase_prices.csv\n",
      "Chunked ingesting: vendor_invoice.csv\n",
      "Chunked ingesting: begin_inventory.csv\n",
      "Chunked ingesting: end_inventory.csv\n",
      "Chunked ingesting: sales.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    if file.endswith('.csv'):\n",
    "        file_path = os.path.join('data', file)\n",
    "        table_name = os.path.splitext(file)[0]\n",
    "        print(f\"Chunked ingesting: {file}\")\n",
    "        ingest_csv_in_chunks(file_path, table_name, engine)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16c33d37-14f0-4f3b-9184-ffce05f3a0b5",
   "metadata": {},
   "source": [
    "table_name = os.path.splitext(file)[0]\n",
    "This line extracts the filename without its extension (like .csv) to use it as the table name for database insertion\n",
    "\n",
    "Breakdown:\n",
    "os.path.splitext(file)\n",
    "    This function splits the filename into two parts:\n",
    "    [0] → the name part (before the extension)\n",
    "    [1] → the extension (like .csv, .txt, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6092af3-4a93-43f9-a4ab-0103112067f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Ensure the logs directory exists\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion_db.log\",\n",
    "    level=logging.DEBUG,  # DEBUG captures everything\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"  # Append mode; use \"w\" to overwrite each time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93fa9e17-1604-4cf7-8115-613a82c84be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def load_raw_data():\n",
    "    '''Load CSVs from data/ and ingest into DB'''\n",
    "    data_dir = 'data'\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        logging.error(f\"Data directory '{data_dir}' does not exist.\")\n",
    "        return\n",
    "    \n",
    "    logging.info(\"Starting to load raw CSV files from 'data' directory.\")\n",
    "\n",
    "    start = time.time()\n",
    "    \n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith('.csv'):\n",
    "            file_path = os.path.join(data_dir, file)\n",
    "            table_name = os.path.splitext(file)[0]\n",
    "            \n",
    "            logging.info(f\"Starting chunked ingestion for file: {file}\")\n",
    "            \n",
    "            try:\n",
    "                ingest_csv_in_chunks(file_path, table_name, engine)\n",
    "                logging.info(f\"Successfully ingested file: {file} into table: {table_name}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to ingest file: {file} — Error: {e}\")\n",
    "    \n",
    "    end = time.time()\n",
    "    total_time = (end - start) / 60  # in minutes\n",
    "    logging.info(\"Finished loading all raw CSV files.\")\n",
    "    logging.info(f\"Total Time Taken: {total_time:.2f} minutes\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d155b3f9-ba5c-45ec-8c2a-ea4dbc6eec3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
